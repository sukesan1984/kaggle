{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from chainer import Chain, optimizers, Variable\n",
    "\n",
    "from chainer.dataset import iterator\n",
    "from chainer.iterators import SerialIterator\n",
    "from chainer.training import Trainer\n",
    "from chainer.training import StandardUpdater\n",
    "import numpy as np\n",
    "import chainer.links as L\n",
    "from chainer.optimizers import AdaGrad, SGD, MomentumSGD\n",
    "from chainer.training.extensions import ProgressBar\n",
    "from chainer.training.extensions import Evaluator, PrintReport, LogReport\n",
    "import chainer.functions as F\n",
    "from chainer.optimizer import WeightDecay\n",
    "from chainer.functions.loss import sigmoid_cross_entropy\n",
    "\n",
    "import chainer.functions as F\n",
    "import chainer.links as L\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn import datasets, model_selection\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "result = pd.read_csv('preprocessed.csv')\n",
    "\n",
    "# Dataを学習データと検証データに分ける\n",
    "#X = result.drop('PassengerId', axis=1).drop('Survived', axis=1).drop('TicketNumber', axis=1).drop('TicketLetter', axis=1).drop('Name', axis=1).fillna(0).values.astype(np.float32)\n",
    "X = result.drop('PassengerId', axis=1).drop('Survived', axis=1).values.astype(np.float32)\n",
    "\n",
    "y = result['Survived'].values.reshape(len(X), -1).astype(np.int32)\n",
    "\n",
    "(x_train, x_test, y_train, y_test) = model_selection.train_test_split(\n",
    "        X,y, test_size=0.3, random_state=0,\n",
    "        )\n",
    "n_examples = len(x_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TitanicModel(Chain):\n",
    "    def __init__(self):\n",
    "        super(TitanicModel, self).__init__(lin=L.Linear(11, 1))\n",
    "\n",
    "    def __call__(self, x):\n",
    "        output = self.lin(x)\n",
    "        return output\n",
    "\n",
    "\n",
    "train_data = [(x_train[i,:], y_train[i]) for i in range(n_examples)]\n",
    "train_iter = SerialIterator(train_data, batch_size = n_examples, repeat=True, shuffle=True)\n",
    "valid_iter = SerialIterator(train_data, batch_size = 1, repeat=False, shuffle=False)\n",
    "titanic_model = TitanicModel()\n",
    "model = L.Classifier(titanic_model, lossfun=sigmoid_cross_entropy.sigmoid_cross_entropy)\n",
    "model.compute_accuracy = False\n",
    "opt = MomentumSGD(lr=0.001)\n",
    "opt.use_cleargrads()\n",
    "opt.setup(model)\n",
    "opt.add_hook(WeightDecay(0.0))\n",
    "updater = StandardUpdater(train_iter, opt, device=-1)\n",
    "trainer = Trainer(updater, (12000, 'epoch'))\n",
    "evaluator = Evaluator(valid_iter, model)\n",
    "\n",
    "trainer.run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5783582089552238\n"
     ]
    }
   ],
   "source": [
    "test_pred = F.sigmoid(titanic_model(x_test)).data\n",
    "test_pred = (test_pred.reshape(len(x_test),) > 0.5).astype(np.int32)\n",
    "size = len(test_pred)\n",
    "correct = 0\n",
    "for i in range(size):\n",
    "    if test_pred[i] == y_train[i]:\n",
    "        correct += 1\n",
    "print(correct/size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(Chain):\n",
    "    \"\"\" 4層のニューラルネットワーク(MLP)\n",
    "    \"\"\"\n",
    "    def __init__(self, n_hid1=100, n_hid2=100, n_out=10):\n",
    "        # Chainer.Chainクラスを敬称して、Chainクラスの機能を使うためにsuper関数を使う\n",
    "        super().__init__()\n",
    "\n",
    "        with self.init_scope():\n",
    "            self.l1 = L.Linear(None, n_hid1)\n",
    "            self.l2 = L.Linear(n_hid1, n_hid2)\n",
    "            self.l3 = L.Linear(n_hid2, n_out)\n",
    "    def __call__(self, x):\n",
    "        hid = F.relu(self.l1(x))\n",
    "        hid2 = F.relu(self.l2(hid))\n",
    "        return self.l3(hid2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model = MLP(10, 10, 2)\n",
    "\n",
    "optimizer = optimizers.SGD()\n",
    "\n",
    "optimizer.setup(model)\n",
    "\n",
    "train_data_variable = Variable(train_data.astype(np.float32))\n",
    "train_label_variable = Variable(train_label.astype(np.int32))\n",
    "\n",
    "loss_log = []\n",
    "for epoch in range(200):\n",
    "    model.cleargrads()\n",
    "\n",
    "    prod_label = model(train_data_variable)\n",
    "    loss = F.softmax_cross_entropy(prod_label, train_label_variable)\n",
    "    loss.backward()\n",
    "    optimizer.update()\n",
    "    loss_log.append(loss.data)\n",
    "\n",
    "plt.plot(loss.data)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
